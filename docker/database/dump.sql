
/*!40000 ALTER TABLE `chat_flow` DISABLE KEYS */;
INSERT INTO `chat_flow` VALUES ('fdd0a58b-0c9c-4740-b40a-9fd47bb957e3','Simple Bot Français','{\"nodes\":[{\"id\":\"llmChain_0\",\"position\":{\"x\":1334.4096361848574,\"y\":704.5225172074731},\"type\":\"customNode\",\"data\":{\"label\":\"LLM Chain\",\"name\":\"llmChain\",\"version\":3,\"type\":\"LLMChain\",\"icon\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chains/LLMChain/LLM_Chain.svg\",\"category\":\"Chains\",\"description\":\"Chain to run queries against LLMs\",\"baseClasses\":[\"LLMChain\",\"BaseChain\",\"Runnable\"],\"inputs\":{\"model\":\"{{chatLocalAI_0.data.instance}}\",\"prompt\":\"{{promptTemplate_0.data.instance}}\",\"outputParser\":\"\",\"inputModeration\":\"\",\"chainName\":\"\"},\"outputs\":{\"output\":\"llmChain\"},\"filePath\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chains/LLMChain/LLMChain.js\",\"inputAnchors\":[{\"label\":\"Language Model\",\"name\":\"model\",\"type\":\"BaseLanguageModel\",\"id\":\"llmChain_0-input-model-BaseLanguageModel\"},{\"label\":\"Prompt\",\"name\":\"prompt\",\"type\":\"BasePromptTemplate\",\"id\":\"llmChain_0-input-prompt-BasePromptTemplate\"},{\"label\":\"Output Parser\",\"name\":\"outputParser\",\"type\":\"BaseLLMOutputParser\",\"optional\":true,\"id\":\"llmChain_0-input-outputParser-BaseLLMOutputParser\"},{\"label\":\"Input Moderation\",\"description\":\"Detect text that could generate harmful output and prevent it from being sent to the language model\",\"name\":\"inputModeration\",\"type\":\"Moderation\",\"optional\":true,\"list\":true,\"id\":\"llmChain_0-input-inputModeration-Moderation\"}],\"inputParams\":[{\"label\":\"Chain Name\",\"name\":\"chainName\",\"type\":\"string\",\"placeholder\":\"Name Your Chain\",\"optional\":true,\"id\":\"llmChain_0-input-chainName-string\"}],\"outputAnchors\":[{\"name\":\"output\",\"label\":\"Output\",\"type\":\"options\",\"description\":\"\",\"options\":[{\"id\":\"llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable\",\"name\":\"llmChain\",\"label\":\"LLM Chain\",\"description\":\"\",\"type\":\"LLMChain | BaseChain | Runnable\"},{\"id\":\"llmChain_0-output-outputPrediction-string|json\",\"name\":\"outputPrediction\",\"label\":\"Output Prediction\",\"description\":\"\",\"type\":\"string | json\"}],\"default\":\"llmChain\"}],\"id\":\"llmChain_0\",\"selected\":false},\"width\":300,\"height\":507,\"selected\":false,\"positionAbsolute\":{\"x\":1334.4096361848574,\"y\":704.5225172074731},\"dragging\":false},{\"id\":\"chatLocalAI_0\",\"position\":{\"x\":942.106244940355,\"y\":176.50115057225923},\"type\":\"customNode\",\"data\":{\"label\":\"ChatLocalAI\",\"name\":\"chatLocalAI\",\"version\":2,\"type\":\"ChatLocalAI\",\"icon\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatLocalAI/localai.png\",\"category\":\"Chat Models\",\"description\":\"Use local LLMs like llama.cpp, gpt4all using LocalAI\",\"baseClasses\":[\"ChatLocalAI\",\"BaseChatModel\",\"BaseChatModel\",\"BaseLanguageModel\",\"Runnable\"],\"credential\":\"\",\"inputs\":{\"cache\":\"\",\"basePath\":\"http://localai:8080\",\"modelName\":\"mistral-openorca\",\"temperature\":0.9,\"maxTokens\":\"\",\"topP\":\"\",\"timeout\":\"\"},\"filePath\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatLocalAI/ChatLocalAI.js\",\"inputAnchors\":[{\"label\":\"Cache\",\"name\":\"cache\",\"type\":\"BaseCache\",\"optional\":true,\"id\":\"chatLocalAI_0-input-cache-BaseCache\"}],\"inputParams\":[{\"label\":\"Connect Credential\",\"name\":\"credential\",\"type\":\"credential\",\"credentialNames\":[\"localAIApi\"],\"optional\":true,\"id\":\"chatLocalAI_0-input-credential-credential\"},{\"label\":\"Base Path\",\"name\":\"basePath\",\"type\":\"string\",\"placeholder\":\"http://localhost:8080/v1\",\"id\":\"chatLocalAI_0-input-basePath-string\"},{\"label\":\"Model Name\",\"name\":\"modelName\",\"type\":\"string\",\"placeholder\":\"gpt4all-lora-quantized.bin\",\"id\":\"chatLocalAI_0-input-modelName-string\"},{\"label\":\"Temperature\",\"name\":\"temperature\",\"type\":\"number\",\"step\":0.1,\"default\":0.9,\"optional\":true,\"id\":\"chatLocalAI_0-input-temperature-number\"},{\"label\":\"Max Tokens\",\"name\":\"maxTokens\",\"type\":\"number\",\"step\":1,\"optional\":true,\"additionalParams\":true,\"id\":\"chatLocalAI_0-input-maxTokens-number\"},{\"label\":\"Top Probability\",\"name\":\"topP\",\"type\":\"number\",\"step\":0.1,\"optional\":true,\"additionalParams\":true,\"id\":\"chatLocalAI_0-input-topP-number\"},{\"label\":\"Timeout\",\"name\":\"timeout\",\"type\":\"number\",\"step\":1,\"optional\":true,\"additionalParams\":true,\"id\":\"chatLocalAI_0-input-timeout-number\"}],\"outputs\":{},\"outputAnchors\":[{\"id\":\"chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|BaseChatModel|BaseLanguageModel|Runnable\",\"name\":\"chatLocalAI\",\"label\":\"ChatLocalAI\",\"description\":\"Use local LLMs like llama.cpp, gpt4all using LocalAI\",\"type\":\"ChatLocalAI | BaseChatModel | BaseChatModel | BaseLanguageModel | Runnable\"}],\"id\":\"chatLocalAI_0\",\"selected\":false},\"width\":300,\"height\":676,\"selected\":false,\"dragging\":false,\"positionAbsolute\":{\"x\":942.106244940355,\"y\":176.50115057225923}},{\"id\":\"promptTemplate_0\",\"position\":{\"x\":519.5373750128662,\"y\":260.67565762920185},\"type\":\"customNode\",\"data\":{\"label\":\"Prompt Template\",\"name\":\"promptTemplate\",\"version\":1,\"type\":\"PromptTemplate\",\"icon\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/prompts/PromptTemplate/prompt.svg\",\"category\":\"Prompts\",\"description\":\"Schema to represent a basic prompt for an LLM\",\"baseClasses\":[\"PromptTemplate\",\"BaseStringPromptTemplate\",\"BasePromptTemplate\",\"Runnable\"],\"inputs\":{\"template\":\"Tu es un assistant qui répond de manière positif et synthétique. Tes réponses seront toujours en Français.\\nTu t\'efforce de répondre directement aux questions sans que l\'utilisateur n\'ai besoin de t\'ajouter des précisions lorsque c\'est possible.\\nSi tu ne sais pas répondre à la question dis simplement que tu ne sais pas mais propose d\'autres question qui te paraissent proche de celle de l\'utilisateur et qu\'il pourrait te poser.\\n\\n{input}\\n\",\"promptValues\":\"\"},\"filePath\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/prompts/PromptTemplate/PromptTemplate.js\",\"inputAnchors\":[],\"inputParams\":[{\"label\":\"Template\",\"name\":\"template\",\"type\":\"string\",\"rows\":4,\"placeholder\":\"What is a good name for a company that makes {product}?\",\"id\":\"promptTemplate_0-input-template-string\"},{\"label\":\"Format Prompt Values\",\"name\":\"promptValues\",\"type\":\"json\",\"optional\":true,\"acceptVariable\":true,\"list\":true,\"id\":\"promptTemplate_0-input-promptValues-json\"}],\"outputs\":{},\"outputAnchors\":[{\"id\":\"promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable\",\"name\":\"promptTemplate\",\"label\":\"PromptTemplate\",\"description\":\"Schema to represent a basic prompt for an LLM\",\"type\":\"PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable\"}],\"id\":\"promptTemplate_0\",\"selected\":false},\"width\":300,\"height\":781,\"selected\":false,\"positionAbsolute\":{\"x\":519.5373750128662,\"y\":260.67565762920185},\"dragging\":false}],\"edges\":[{\"source\":\"chatLocalAI_0\",\"sourceHandle\":\"chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|BaseChatModel|BaseLanguageModel|Runnable\",\"target\":\"llmChain_0\",\"targetHandle\":\"llmChain_0-input-model-BaseLanguageModel\",\"type\":\"buttonedge\",\"id\":\"chatLocalAI_0-chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel\"},{\"source\":\"promptTemplate_0\",\"sourceHandle\":\"promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable\",\"target\":\"llmChain_0\",\"targetHandle\":\"llmChain_0-input-prompt-BasePromptTemplate\",\"type\":\"buttonedge\",\"id\":\"promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate\"}],\"viewport\":{\"x\":216.2084631230764,\"y\":-90.82797787512243,\"zoom\":0.7036306213081317}}',0,0,NULL,NULL,'2024-03-07 15:56:10.106900','2024-03-09 14:53:50.000000',NULL,NULL,NULL,NULL);


INSERT INTO `variable` VALUES 
('374b9a3c-7ad3-43d8-8d31-c1c5f2602557','databaseHostname','database','static','2024-03-09 08:42:17.115661','2024-03-09 08:45:30.000000'),
('5c1e4e07-edb6-4850-9a56-2e85b625ad2f','databaseUser','aisuite','static','2024-03-09 08:42:44.077285','2024-03-09 08:42:44.077285'),
('630880c9-3065-4b72-869b-9ea27b6c04c2','analysedTable','analyse','static','2024-03-09 14:52:11.915475','2024-03-09 14:52:11.915475'),
('b4ee876a-be58-47d5-95d5-2923101059c9','databaseDatabase','aisuite','static','2024-03-09 08:43:12.885048','2024-03-09 08:43:12.885048'),
('e03110eb-54a0-4bf8-9d7a-7a378edf2a66','databasePassword','aisuite','static','2024-03-09 08:42:54.815903','2024-03-09 08:42:54.815903');


INSERT INTO `chat_flow` VALUES ('9a7e03ea-0cfc-45c2-bf76-6e68da54c9d3','Bot conversationnal Français','{\"nodes\":[{\"id\":\"chatPromptTemplate_0\",\"position\":{\"x\":-220.26548672566364,\"y\":240.05309734513276},\"type\":\"customNode\",\"data\":{\"label\":\"Chat Prompt Template\",\"name\":\"chatPromptTemplate\",\"version\":1,\"type\":\"ChatPromptTemplate\",\"icon\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/prompts/ChatPromptTemplate/prompt.svg\",\"category\":\"Prompts\",\"description\":\"Schema to represent a chat prompt\",\"baseClasses\":[\"ChatPromptTemplate\",\"BaseChatPromptTemplate\",\"BasePromptTemplate\",\"Runnable\"],\"inputs\":{\"systemMessagePrompt\":\"Tu es un assistant qui répond de manière positif et synthétique. Tes réponses seront toujours en Français.\\nTu t\'efforce de répondre directement aux questions sans que l\'utilisateur n\'ai besoin de t\'ajouter des précisions lorsque c\'est possible.\\nSi tu ne sais pas répondre à la question dis simplement que tu ne sais pas mais propose d\'autres question qui te paraissent proche de celle de l\'utilisateur et qu\'il pourrait te poser.\\n\",\"humanMessagePrompt\":\"{input}\",\"promptValues\":\"\"},\"filePath\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/prompts/ChatPromptTemplate/ChatPromptTemplate.js\",\"inputAnchors\":[],\"inputParams\":[{\"label\":\"System Message\",\"name\":\"systemMessagePrompt\",\"type\":\"string\",\"rows\":4,\"placeholder\":\"You are a helpful assistant that translates {input_language} to {output_language}.\",\"id\":\"chatPromptTemplate_0-input-systemMessagePrompt-string\"},{\"label\":\"Human Message\",\"name\":\"humanMessagePrompt\",\"type\":\"string\",\"rows\":4,\"placeholder\":\"{text}\",\"id\":\"chatPromptTemplate_0-input-humanMessagePrompt-string\"},{\"label\":\"Format Prompt Values\",\"name\":\"promptValues\",\"type\":\"json\",\"optional\":true,\"acceptVariable\":true,\"list\":true,\"id\":\"chatPromptTemplate_0-input-promptValues-json\"}],\"outputs\":{},\"outputAnchors\":[{\"id\":\"chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable\",\"name\":\"chatPromptTemplate\",\"label\":\"ChatPromptTemplate\",\"description\":\"Schema to represent a chat prompt\",\"type\":\"ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable\"}],\"id\":\"chatPromptTemplate_0\",\"selected\":false},\"width\":300,\"height\":1228,\"selected\":false,\"dragging\":false,\"positionAbsolute\":{\"x\":-220.26548672566364,\"y\":240.05309734513276}},{\"id\":\"chatLocalAI_0\",\"position\":{\"x\":540.3805309734513,\"y\":271.67994100294993},\"type\":\"customNode\",\"data\":{\"label\":\"ChatLocalAI\",\"name\":\"chatLocalAI\",\"version\":2,\"type\":\"ChatLocalAI\",\"icon\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatLocalAI/localai.png\",\"category\":\"Chat Models\",\"description\":\"Use local LLMs like llama.cpp, gpt4all using LocalAI\",\"baseClasses\":[\"ChatLocalAI\",\"BaseChatModel\",\"BaseChatModel\",\"BaseLanguageModel\",\"Runnable\"],\"credential\":\"\",\"inputs\":{\"cache\":\"\",\"basePath\":\"http://localai:8080\",\"modelName\":\"mistral-openorca\",\"temperature\":0.9,\"maxTokens\":\"\",\"topP\":\"\",\"timeout\":\"\"},\"filePath\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chatmodels/ChatLocalAI/ChatLocalAI.js\",\"inputAnchors\":[{\"label\":\"Cache\",\"name\":\"cache\",\"type\":\"BaseCache\",\"optional\":true,\"id\":\"chatLocalAI_0-input-cache-BaseCache\"}],\"inputParams\":[{\"label\":\"Connect Credential\",\"name\":\"credential\",\"type\":\"credential\",\"credentialNames\":[\"localAIApi\"],\"optional\":true,\"id\":\"chatLocalAI_0-input-credential-credential\"},{\"label\":\"Base Path\",\"name\":\"basePath\",\"type\":\"string\",\"placeholder\":\"http://localhost:8080/v1\",\"id\":\"chatLocalAI_0-input-basePath-string\"},{\"label\":\"Model Name\",\"name\":\"modelName\",\"type\":\"string\",\"placeholder\":\"gpt4all-lora-quantized.bin\",\"id\":\"chatLocalAI_0-input-modelName-string\"},{\"label\":\"Temperature\",\"name\":\"temperature\",\"type\":\"number\",\"step\":0.1,\"default\":0.9,\"optional\":true,\"id\":\"chatLocalAI_0-input-temperature-number\"},{\"label\":\"Max Tokens\",\"name\":\"maxTokens\",\"type\":\"number\",\"step\":1,\"optional\":true,\"additionalParams\":true,\"id\":\"chatLocalAI_0-input-maxTokens-number\"},{\"label\":\"Top Probability\",\"name\":\"topP\",\"type\":\"number\",\"step\":0.1,\"optional\":true,\"additionalParams\":true,\"id\":\"chatLocalAI_0-input-topP-number\"},{\"label\":\"Timeout\",\"name\":\"timeout\",\"type\":\"number\",\"step\":1,\"optional\":true,\"additionalParams\":true,\"id\":\"chatLocalAI_0-input-timeout-number\"}],\"outputs\":{},\"outputAnchors\":[{\"id\":\"chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|BaseChatModel|BaseLanguageModel|Runnable\",\"name\":\"chatLocalAI\",\"label\":\"ChatLocalAI\",\"description\":\"Use local LLMs like llama.cpp, gpt4all using LocalAI\",\"type\":\"ChatLocalAI | BaseChatModel | BaseChatModel | BaseLanguageModel | Runnable\"}],\"id\":\"chatLocalAI_0\",\"selected\":false},\"width\":300,\"height\":676,\"selected\":false,\"dragging\":false,\"positionAbsolute\":{\"x\":540.3805309734513,\"y\":271.67994100294993}},{\"id\":\"conversationChain_0\",\"position\":{\"x\":944.8171091445429,\"y\":991.4174041297936},\"type\":\"customNode\",\"data\":{\"label\":\"Conversation Chain\",\"name\":\"conversationChain\",\"version\":3,\"type\":\"ConversationChain\",\"icon\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chains/ConversationChain/conv.svg\",\"category\":\"Chains\",\"description\":\"Chat models specific conversational chain with memory\",\"baseClasses\":[\"ConversationChain\",\"LLMChain\",\"BaseChain\",\"Runnable\"],\"inputs\":{\"model\":\"{{chatLocalAI_0.data.instance}}\",\"memory\":\"{{RedisBackedChatMemory_0.data.instance}}\",\"chatPromptTemplate\":\"{{chatPromptTemplate_0.data.instance}}\",\"inputModeration\":\"\",\"systemMessagePrompt\":\"\"},\"filePath\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/chains/ConversationChain/ConversationChain.js\",\"inputAnchors\":[{\"label\":\"Chat Model\",\"name\":\"model\",\"type\":\"BaseChatModel\",\"id\":\"conversationChain_0-input-model-BaseChatModel\"},{\"label\":\"Memory\",\"name\":\"memory\",\"type\":\"BaseMemory\",\"id\":\"conversationChain_0-input-memory-BaseMemory\"},{\"label\":\"Chat Prompt Template\",\"name\":\"chatPromptTemplate\",\"type\":\"ChatPromptTemplate\",\"description\":\"Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable\",\"optional\":true,\"id\":\"conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate\"},{\"label\":\"Input Moderation\",\"description\":\"Detect text that could generate harmful output and prevent it from being sent to the language model\",\"name\":\"inputModeration\",\"type\":\"Moderation\",\"optional\":true,\"list\":true,\"id\":\"conversationChain_0-input-inputModeration-Moderation\"}],\"inputParams\":[{\"label\":\"System Message\",\"name\":\"systemMessagePrompt\",\"type\":\"string\",\"rows\":4,\"description\":\"If Chat Prompt Template is provided, this will be ignored\",\"additionalParams\":true,\"optional\":true,\"default\":\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\",\"placeholder\":\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\",\"id\":\"conversationChain_0-input-systemMessagePrompt-string\"}],\"outputs\":{},\"outputAnchors\":[{\"id\":\"conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable\",\"name\":\"conversationChain\",\"label\":\"ConversationChain\",\"description\":\"Chat models specific conversational chain with memory\",\"type\":\"ConversationChain | LLMChain | BaseChain | Runnable\"}],\"id\":\"conversationChain_0\",\"selected\":false},\"width\":300,\"height\":434,\"selected\":false,\"positionAbsolute\":{\"x\":944.8171091445429,\"y\":991.4174041297936},\"dragging\":false},{\"id\":\"RedisBackedChatMemory_0\",\"position\":{\"x\":181.17699115044252,\"y\":861.0398230088497},\"type\":\"customNode\",\"data\":{\"label\":\"Redis-Backed Chat Memory\",\"name\":\"RedisBackedChatMemory\",\"version\":2,\"type\":\"RedisBackedChatMemory\",\"icon\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/memory/RedisBackedChatMemory/redis.svg\",\"category\":\"Memory\",\"description\":\"Summarizes the conversation and stores the memory in Redis server\",\"baseClasses\":[\"RedisBackedChatMemory\",\"BaseChatMemory\",\"BaseMemory\"],\"credential\":\"2847a6c3-de17-4305-ad2f-a537defeb372\",\"inputs\":{\"sessionId\":\"\",\"sessionTTL\":\"\",\"memoryKey\":\"chat_history\",\"windowSize\":\"\"},\"filePath\":\"/usr/local/lib/node_modules/flowise/node_modules/flowise-components/dist/nodes/memory/RedisBackedChatMemory/RedisBackedChatMemory.js\",\"inputAnchors\":[],\"inputParams\":[{\"label\":\"Connect Credential\",\"name\":\"credential\",\"type\":\"credential\",\"optional\":true,\"credentialNames\":[\"redisCacheApi\",\"redisCacheUrlApi\"],\"id\":\"RedisBackedChatMemory_0-input-credential-credential\"},{\"label\":\"Session Id\",\"name\":\"sessionId\",\"type\":\"string\",\"description\":\"If not specified, a random id will be used. Learn <a target=\\\"_blank\\\" href=\\\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\\\">more</a>\",\"default\":\"\",\"additionalParams\":true,\"optional\":true,\"id\":\"RedisBackedChatMemory_0-input-sessionId-string\"},{\"label\":\"Session Timeouts\",\"name\":\"sessionTTL\",\"type\":\"number\",\"description\":\"Omit this parameter to make sessions never expire\",\"additionalParams\":true,\"optional\":true,\"id\":\"RedisBackedChatMemory_0-input-sessionTTL-number\"},{\"label\":\"Memory Key\",\"name\":\"memoryKey\",\"type\":\"string\",\"default\":\"chat_history\",\"additionalParams\":true,\"id\":\"RedisBackedChatMemory_0-input-memoryKey-string\"},{\"label\":\"Window Size\",\"name\":\"windowSize\",\"type\":\"number\",\"description\":\"Window of size k to surface the last k back-and-forth to use as memory.\",\"additionalParams\":true,\"optional\":true,\"id\":\"RedisBackedChatMemory_0-input-windowSize-number\"}],\"outputs\":{},\"outputAnchors\":[{\"id\":\"RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory\",\"name\":\"RedisBackedChatMemory\",\"label\":\"RedisBackedChatMemory\",\"description\":\"Summarizes the conversation and stores the memory in Redis server\",\"type\":\"RedisBackedChatMemory | BaseChatMemory | BaseMemory\"}],\"id\":\"RedisBackedChatMemory_0\",\"selected\":false},\"width\":300,\"height\":329,\"selected\":false,\"positionAbsolute\":{\"x\":181.17699115044252,\"y\":861.0398230088497},\"dragging\":false}],\"edges\":[{\"source\":\"chatLocalAI_0\",\"sourceHandle\":\"chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|BaseChatModel|BaseLanguageModel|Runnable\",\"target\":\"conversationChain_0\",\"targetHandle\":\"conversationChain_0-input-model-BaseChatModel\",\"type\":\"buttonedge\",\"id\":\"chatLocalAI_0-chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|BaseChatModel|BaseLanguageModel|Runnable-conversationChain_0-conversationChain_0-input-model-BaseChatModel\"},{\"source\":\"chatPromptTemplate_0\",\"sourceHandle\":\"chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable\",\"target\":\"conversationChain_0\",\"targetHandle\":\"conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate\",\"type\":\"buttonedge\",\"id\":\"chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-conversationChain_0-conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate\"},{\"source\":\"RedisBackedChatMemory_0\",\"sourceHandle\":\"RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory\",\"target\":\"conversationChain_0\",\"targetHandle\":\"conversationChain_0-input-memory-BaseMemory\",\"type\":\"buttonedge\",\"id\":\"RedisBackedChatMemory_0-RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory-conversationChain_0-conversationChain_0-input-memory-BaseMemory\"}],\"viewport\":{\"x\":665.6089362099856,\"y\":-105.80580239569593,\"zoom\":0.5922416345869114}}',0,0,NULL,NULL,'2024-03-07 16:17:51.432511','2024-03-09 15:02:32.000000',NULL,NULL,NULL,NULL);







/*!40000 ALTER TABLE `chat_flow` ENABLE KEYS */;

